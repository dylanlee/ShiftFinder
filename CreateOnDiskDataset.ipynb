{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating study area array\n",
    "The purpose of this notebook is to take in geotiff's of surface water data and collate them together into one large array that the analysis can be run on.\n",
    "\n",
    "To do this you need to understand the EarthEngine GeoTiff naming convention. When you exporting the surface water dataset to GeoTIFF(s) from earth engine, the image is split into tiles. The filename of each tile will be in the form baseFilename-yMin-xMin where xMin and yMin are the coordinates of each tile within the overall bounding box of the exported image. These are the image names given in the images of the folder \"EarthEngineAltiplano\" of the zenodo dataset.\n",
    "\n",
    "Once you understand the naming convention of the tiles you can create an order that allows you to merge them together in a way that is geographically contiguous. One such ordering was created for the current collating script and the images were renamed by this order in the folder \"AltiPlanoProcessOrder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import array\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import h5py\n",
    "#need to import the warp module seperately\n",
    "import rasterio.warp\n",
    "import rasterio.merge\n",
    "import matplotlib.pyplot as plt\n",
    "import avul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing images in AltiPlanoProcessOrder folder \n",
    "Cell below takes in the geotiffs in the AltiPlanoProcessOrder folder using the ordering implied by their names loads them into memory and then appends them onto a list of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundingBox(left=-71.61791653184363, bottom=-16.196085583504487, right=-68.58232952374695, top=-13.1604985754078)\n",
      "BoundingBox(left=-68.58232952374695, bottom=-16.196085583504487, right=-65.54674251565027, top=-13.1604985754078)\n",
      "BoundingBox(left=-65.54674251565027, bottom=-16.196085583504487, right=-64.45475045627458, top=-13.1604985754078)\n",
      "BoundingBox(left=-71.61791653184363, bottom=-19.231672591601175, right=-68.58232952374695, top=-16.196085583504487)\n",
      "BoundingBox(left=-68.58232952374695, bottom=-19.231672591601175, right=-65.54674251565027, top=-16.196085583504487)\n",
      "BoundingBox(left=-65.54674251565027, bottom=-19.231672591601175, right=-64.45475045627458, top=-16.196085583504487)\n",
      "BoundingBox(left=-71.61791653184363, bottom=-22.267259599697862, right=-68.58232952374695, top=-19.231672591601175)\n",
      "BoundingBox(left=-68.58232952374695, bottom=-22.267259599697862, right=-65.54674251565027, top=-19.231672591601175)\n",
      "BoundingBox(left=-65.54674251565027, bottom=-22.267259599697862, right=-64.45475045627458, top=-19.231672591601175)\n",
      "BoundingBox(left=-71.61791653184363, bottom=-23.22719931230798, right=-68.58232952374695, top=-22.26725959969786)\n",
      "BoundingBox(left=-68.58232952374695, bottom=-23.22719931230798, right=-65.54674251565027, top=-22.26725959969786)\n",
      "BoundingBox(left=-65.54674251565027, bottom=-23.22719931230798, right=-64.45475045627458, top=-22.26725959969786)\n"
     ]
    }
   ],
   "source": [
    "#import the surface water dataset\n",
    "datasets = []\n",
    "left = 0\n",
    "bottom = 0\n",
    "right = -100\n",
    "top = -100\n",
    "for x in range(1,13):\n",
    "    \n",
    "    dataset = rasterio.open('../Data/AltiPlano/AltiPlanoProccessOrder/AltiPlanoYearly'+str(x)+'.tif')\n",
    "    print(dataset.bounds)\n",
    "    left1 = dataset.bounds[0]\n",
    "    bottom1 = dataset.bounds[1]\n",
    "    right1 = dataset.bounds[2]\n",
    "    top1 = dataset.bounds[3]\n",
    "    #Get the bounds of the whole area being collated\n",
    "    if left1 < left:\n",
    "        left = left1\n",
    "    if bottom1 < bottom:\n",
    "        bottom = bottom1\n",
    "    if right1 > right:\n",
    "        right = right1\n",
    "    if top1 > top:\n",
    "        top = top1\n",
    "        \n",
    "    #append to dataset list\n",
    "    datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-71.61791653184363 -23.22719931230798 -64.45475045627458 -13.1604985754078\n"
     ]
    }
   ],
   "source": [
    "#double check that the bounds are the bounds of the area you exported from Earth Engine. For the current\n",
    "#study area these are approx: -71.62, -23.23, -64.45,-13.16 \n",
    "print(left,bottom,right,top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the bounds obtained during collating the data to create a transform that maps pixels to coordinates\n",
    "Tran = rasterio.transform.from_bounds(left, bottom, right, top, 26580, 37354)\n",
    "rasterio.transform.xy(Tran, 1, 1, offset='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge datasets together and write them to disk\n",
    "Now that we have a list of geotiff datasets to read and have them listed in the right order we can read them into memory one at a time and then write them to disk. This is what the cell bellow does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1,36):\n",
    "    for y in range(len(datasets)):\n",
    "        print(y)\n",
    "        dataset = datasets[y]\n",
    "        arr = dataset.read(x)\n",
    "        if y < 3:\n",
    "            if y == 0:\n",
    "                fRow = arr\n",
    "            else:\n",
    "                fRow = np.concatenate([fRow,arr],1)\n",
    "        if y >= 3 and y < 6:\n",
    "            if y == 3:\n",
    "                sRow = arr\n",
    "            else:\n",
    "                sRow = np.concatenate([sRow,arr],1)\n",
    "        if y >=6 and y < 9: \n",
    "            if y == 6:\n",
    "                tRow = arr\n",
    "            else:\n",
    "                tRow = np.concatenate([tRow,arr],1)\n",
    "        if y >= 9:\n",
    "            if y == 9:\n",
    "                foRow = arr\n",
    "            else:\n",
    "                foRow = np.concatenate([foRow,arr],1)\n",
    "                \n",
    "    tallFRow = fRow.reshape((1,)+fRow.shape)\n",
    "    tallSRow = sRow.reshape((1,)+sRow.shape)\n",
    "    tallTRow = tRow.reshape((1,)+tRow.shape)\n",
    "    tallFoRow = foRow.reshape((1,)+foRow.shape)\n",
    "\n",
    "    OneYrOcc = np.hstack([tallFRow,tallSRow,tallTRow,tallFoRow])\n",
    "        \n",
    "    if x == 1:\n",
    "        hf = h5py.File('Altiplano.h5', 'w')\n",
    "        hf.create_dataset('Altiplano',data=OneYrOcc, dtype='u2', compression=\"gzip\", chunks=True, maxshape=(None,None,None))\n",
    "    if x > 1:\n",
    "        hf[\"Altiplano\"].resize((hf[\"Altiplano\"].shape[0] + 1), axis = 0)\n",
    "        hf[\"Altiplano\"][-1:] = OneYrOcc\n",
    "#call this to write to disk\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting subset to be analyzed\n",
    "The cells below take a subset of the larger area created in the cells above. This subset is what will be analyzed in the notebooks \"RunTiles.ipynb\" and \"VizResults.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use line below once to reopen the dataset after writing\n",
    "#need to use the 'r' option instead of 'a' for dask distributed to work\n",
    "hf = h5py.File('../Data/Altiplano.h5','r')\n",
    "d = hf['./Altiplano']          # Pointer on on-disk array\n",
    "\n",
    "#convert the on-disk array to a dask array\n",
    "Im = array.from_array(d,chunks='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Im = Im.astype('uint8') #convert to unsigned int 8 to save space\n",
    "\n",
    "#trim and rechunk matrix\n",
    "\n",
    "#Study area \n",
    "#Im = Im[0:35,0:16384,10016:26400]\n",
    "\n",
    "#small test area for computers with less memory than 32gb\n",
    "Im = Im[0:35,0:5464,10016:15480]\n",
    "\n",
    "#load trimmed study region into memory\n",
    "Im = Im.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 5464, 5464)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#study area image shape should be (35,16384,16384)\n",
    "#small test area shape should be (35,5464,5464)\n",
    "Im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now import the mask dataset. Only doing this here so it can be \n",
    "#cropped if necessary for testing on a lower memory machine. \n",
    "mask = plt.imread('../Data/WholeTestAreaTempCenterlinesThreshold1.png')\n",
    "mask[mask == 255] = 1\n",
    "#trim mask if running small test window\n",
    "cutmask = mask[0:5464,0:5464]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-68.91852401882868,\n",
       "  -67.44600560509997,\n",
       "  -68.91852401882868,\n",
       "  -67.44600560509997],\n",
       " [-13.160633322700418,\n",
       "  -13.160633322700418,\n",
       "  -14.633151736429138,\n",
       "  -14.633151736429138])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get lat-long locations of corners of cropped image of the final test region. This is helpful\n",
    "#in a later part of the analysis when you need to get another transform\n",
    "#to determine the geographical center of active region. See \"VizResults.ipynb\"\n",
    "left = -71.61791653184363 \n",
    "bottom = -23.22719931230798 \n",
    "right = -64.45475045627458 \n",
    "top = -13.1604985754078\n",
    "Tran = rasterio.transform.from_bounds(left, bottom, right, top, 26580, 37354)\n",
    "#get new corners for full study area\n",
    "#rasterio.transform.xy(Tran, [0,0,16384,16384], [10016,26400,10016,26400], offset='center')\n",
    "#get new corners for small test area\n",
    "rasterio.transform.xy(Tran, [0,0,5464,5464], [10016,15480,10016,15480], offset='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save image and mask that will be analyzed in the \"RunTiles\" notebook\n",
    "#if TestRegion.h5 already exists you will get an error message when you try to run the line below. To run delete\n",
    "#old TestRegion.h5 or rename\n",
    "shf = h5py.File('../Data/TestRegion.h5','w')\n",
    "shf.create_dataset('Altiplano',data=Im, dtype='u2', compression=\"gzip\", chunks=True, maxshape=(None,None,None))\n",
    "shf.close()\n",
    "plt.imsave('../Data/TestRegionMask.png',cutmask,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
